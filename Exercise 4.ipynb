{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMTkknIKXl7dxwgNMhAnhu+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Exercise 4**\n","\n","1 Changing the batch_size from 32 to 64 triggers the structural bug.\n","ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size\n","\n"," This size mismatch likely arises because we are concatenating real and generated samples before feeding them into the discriminator, and there might be a discrepancy in the batch sizes between the real and generated samples.\n","\n","To fix this, we need to ensure that the sizes of the real and generated samples match before concatenating them. so we should adjust the batch size used for generating the samples to match the batch size of the real samples as below:\n","\n","all_samples = torch.cat((real_samples, generated_samples))\n","all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n","batch_size_all_samples = all_samples.size(0)\n","batch_size_all_samples_labels = all_samples_labels.size(0)\n","if batch_size_all_samples != batch_size_all_samples_labels:\n","    min_batch_size = min(batch_size_all_samples, batch_size_all_samples_labels)\n","    all_samples = all_samples[:min_batch_size]\n","    all_samples_labels = all_samples_labels[:min_batch_size]\n","\n","\n","\n","2 Can you also spot the cosmetic bug?\n","\n","\n","x = x.view(x.size(0), 784)\n","This line assumes that the input size is always 784, which may not be the case if the batch size is changed. To fix this bug, we should ensure that the reshaping is done dynamically based on the actual input size. We can achieve this by calculating the input size based on the shape of the input as below:\n","x = x.view(x.size(0), -1)"],"metadata":{"id":"CpYN-530Zads"}},{"cell_type":"code","source":["import torch\n","import torch.utils\n","import torch.utils.data\n","import torch.nn as nn\n","import torchvision\n","NoneType = type(None)\n","from IPython.display import display, clear_output\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import torchvision.transforms.functional as TF\n","from torchvision.models import vgg11\n","from torchvision.models import mobilenet_v2\n","import torchvision.transforms as transforms\n","import time"],"metadata":{"id":"APKn9f6mV0b8","executionInfo":{"status":"ok","timestamp":1715155310251,"user_tz":-210,"elapsed":10018,"user":{"displayName":"Mahshid Zamanvaziri","userId":"13256608424001221562"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kkPAQ8cASu1w","executionInfo":{"status":"ok","timestamp":1715155310252,"user_tz":-210,"elapsed":14,"user":{"displayName":"Mahshid Zamanvaziri","userId":"13256608424001221562"}}},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","class Generator(nn.Module):\n","    \"\"\"\n","    Generator class for the GAN\n","    \"\"\"\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(100, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 784),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        output = output.view(x.size(0), 1, 28, 28)\n","        return output\n"]},{"cell_type":"code","source":["# You can copy this code to your personal pipeline project or execute it here.\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    Discriminator class for the GAN\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(784, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        output = self.model(x)\n","        return output"],"metadata":{"id":"fNliU8sES39P","executionInfo":{"status":"ok","timestamp":1715155310253,"user_tz":-210,"elapsed":13,"user":{"displayName":"Mahshid Zamanvaziri","userId":"13256608424001221562"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# You can copy this code to your personal pipeline project or execute it here.\n","def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n","    # Add/adjust code.\n","\n","    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","    try:\n","        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n","    except:\n","        print(\"Failed to download MNIST, retrying with different URL\")\n","        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n","        torchvision.datasets.MNIST.resources = [\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n","             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n","             'd53e105ee54ea40749a09fcbcd1e9432'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n","             '9fb629c4189551a2d022fa330f9573f3'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n","             'ec29112dd5afa0611ce80d1b7f02629c')\n","        ]\n","        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n","\n","    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","\n","    # example data\n","    real_samples, mnist_labels = next(iter(train_loader))\n","\n","    fig = plt.figure()\n","    for i in range(16):\n","        sub = fig.add_subplot(4, 4, 1 + i)\n","        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","        sub.axis('off')\n","\n","    fig.tight_layout()\n","    fig.suptitle(\"Real images\")\n","    display(fig)\n","\n","    time.sleep(5)\n","\n","    # Set up training\n","    discriminator = Discriminator().to(device)\n","    generator = Generator().to(device)\n","    lr = 0.0001\n","    loss_function = nn.BCELoss()\n","    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n","    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n","\n","    # train\n","    for epoch in range(num_epochs):\n","        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n","\n","            # Data for training the discriminator\n","            real_samples = real_samples.to(device=device)\n","            real_samples_labels = torch.ones((batch_size, 1)).to(device=device)\n","            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n","            generated_samples = generator(latent_space_samples)\n","            generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)\n","            all_samples = torch.cat((real_samples, generated_samples))\n","            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n","# Bug fixing-------------------------------------------------------------------\n","            # Concatenate real and generated samples along with their labels\n","            all_samples = torch.cat((real_samples, generated_samples))\n","            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n","\n","            # Ensure that the batch size of all_samples and all_samples_labels match\n","            batch_size_all_samples = all_samples.size(0)\n","            batch_size_all_samples_labels = all_samples_labels.size(0)\n","\n","            # Check if batch sizes match, adjust if necessary\n","            if batch_size_all_samples != batch_size_all_samples_labels:\n","                min_batch_size = min(batch_size_all_samples, batch_size_all_samples_labels)\n","                all_samples = all_samples[:min_batch_size]\n","                all_samples_labels = all_samples_labels[:min_batch_size]\n","# End of bug fixing-----------------------------------------------------------\n","\n","            # Training the discriminator\n","            discriminator.zero_grad()\n","            output_discriminator = discriminator(all_samples)\n","            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n","            loss_discriminator.backward()\n","            optimizer_discriminator.step()\n","\n","            # Data for training the generator\n","            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n","\n","            # Training the generator\n","            generator.zero_grad()\n","            generated_samples = generator(latent_space_samples)\n","            output_discriminator_generated = discriminator(generated_samples)\n","            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n","            loss_generator.backward()\n","            optimizer_generator.step()\n","\n","            # Show loss and samples generated\n","            if n == batch_size - 1:\n","                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n","                generated_samples = generated_samples.detach().cpu().numpy()\n","                fig = plt.figure()\n","                for i in range(16):\n","                    sub = fig.add_subplot(4, 4, 1 + i)\n","                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","                    sub.axis('off')\n","                fig.suptitle(name)\n","                fig.tight_layout()\n","                clear_output(wait=False)\n","                display(fig)\n"],"metadata":{"id":"UZLwiZr7U0h2","executionInfo":{"status":"ok","timestamp":1715155310253,"user_tz":-210,"elapsed":12,"user":{"displayName":"Mahshid Zamanvaziri","userId":"13256608424001221562"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_gan(batch_size=64, num_epochs=100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EytNw544Y_qLSQ8aelyt-UxUIJWWTQev"},"id":"OkC429uNU2Bj","executionInfo":{"status":"ok","timestamp":1715157203841,"user_tz":-210,"elapsed":1892473,"user":{"displayName":"Mahshid Zamanvaziri","userId":"13256608424001221562"}},"outputId":"c0c6ed43-5649-48ea-a9af-3149a7744df7"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}